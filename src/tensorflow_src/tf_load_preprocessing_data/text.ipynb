{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "explicit-labor",
   "metadata": {},
   "source": [
    "# 1.Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sunset-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import utils_text\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recorded-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "TAKE_SIZE = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-recorder",
   "metadata": {},
   "source": [
    "# 2.将文本加载到数据集中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-extreme",
   "metadata": {},
   "source": [
    "## 数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "generous-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/zfwang/.keras/datasets/cowper.txt',\n",
       " '/Users/zfwang/.keras/datasets/derby.txt',\n",
       " '/Users/zfwang/.keras/datasets/butler.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIRECTORY_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/illiad/\"\n",
    "FILE_NAMES = [\"cowper.txt\", \"derby.txt\", \"butler.txt\"]\n",
    "all_text_paths = utils_text.get_text_paths(data_url = DIRECTORY_URL, file_name = FILE_NAMES)\n",
    "all_text_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-conversion",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "maritime-syndicate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: ((), ()), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labeled_data = utils_text.get_labeled_data(parent_dir = os.path.dirname(all_text_paths[0]), file_names = FILE_NAMES, buffer_size = BUFFER_SIZE)\n",
    "all_labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bronze-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"Below the brain; his teeth were shatter'd all;\">, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"Once deem'd effeminate, but dragging now\">, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Achilles! such I made thee. For with me,'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'THE fight between Trojans and Achaeans was now left to rage as it'>, <tf.Tensor: shape=(), dtype=int64, numpy=2>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'The flying steeds were dragging towards the ships;'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
     ]
    }
   ],
   "source": [
    "for ex in all_labeled_data.take(5):\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-husband",
   "metadata": {},
   "source": [
    "# 3.将本文编码成数字"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-combining",
   "metadata": {},
   "source": [
    "## 建立词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yellow-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size is 17178\n"
     ]
    }
   ],
   "source": [
    "vocabulary_set = utils_text.build_token_set(all_labeled_data)\n",
    "vocabulary_size = len(vocabulary_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-anthropology",
   "metadata": {},
   "source": [
    "## 样本编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broad-chick",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "map() got an unexpected keyword argument 'vocabulary_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d08206af344d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_encoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_labeled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_map_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: map() got an unexpected keyword argument 'vocabulary_set'"
     ]
    }
   ],
   "source": [
    "all_encoded_data = all_labeled_data.map(utils_text.encode_map_fn, vocabulary_set = vocabulary_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-survey",
   "metadata": {},
   "source": [
    "# 分割训练数据、验证数据、测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "distinguished-ordinance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 2584  3838  7022  6994  3742 12016   879     0     0     0     0     0\n",
      "     0     0     0], shape=(15,), dtype=int64) tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = utils_text.split_train_test(all_encoded_data = all_encoded_data, take_size = TAKE_SIZE, buffer_size = BUFFER_SIZE, batch_size = BATCH_SIZE)\n",
    "sample_text, sample_labels = next(iter(test_data))\n",
    "print(sample_text[0], sample_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-validation",
   "metadata": {},
   "source": [
    "# 建立基于 LSTM 的分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "# 模型构建\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocabulary_size, 64))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "for units in [64, 64]:\n",
    "    model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(3, activation = \"softmax\"))\n",
    "\n",
    "# 模型编译\n",
    "model.compile(\n",
    "    optimizer = \"adam\", \n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 模型训练\n",
    "model.fit(train_data, epochs = 3, validation_data = test_data)\n",
    "\n",
    "# 模型评估\n",
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print(f\"\\nEval loss: {test_loss}, Eval accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
