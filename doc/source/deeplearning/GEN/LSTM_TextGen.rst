
LSTM 生成文本
=====================

本节将会探讨如何将循环神经网络用于生成序列数据。将以文本生成为例，但同样的
技术也可以推广到任何类型的序列数据，可以将其应用于音符序列来生成新音乐，也可以
应用于笔画数据的时间序列，以此类推。

序列数据生成绝不仅限于艺术内容生成。它已经成功应用与语音合成和聊天机器人的对话生成。
Google 于 2016 年发布的 Smart Reply (智能回复)功能，能够对电子邮件或短信自动生成
一组快速回复，采用的也是相似的技术。


1.生成式循环网络简史
----------------------

截至 2014 年年底，还没什么人见过 LSTM 这一缩写，即使在机器学习领域也不常见。
用循环网络生成序列数据的成功应用在 2016 年才开始出现在主流领域。但是，这些技术都
有着相当长的历史，最早的是 1997 年开发的 LSTM 算法。这一算法早期用于逐字符的生成文本。






2.如何生成序列数据
-----------------------

用深度学习生成序列数据的通用方法，就是使用前面的标记作为输入，
训练一个网络(通常是循环神经网络或卷积神经网络)来预测序列中接下来
的一个或多个标记。

例如，给定输入 ``the cat is on the ma``，训练网络来预测目标 ``t``，即下一个字符。

与前面处理文本数据时一样，**标记(token)** 通常是单词或字符，给定前面的标记，
能够对下一个标记的概率进行建模的任何网络都叫做 **语言模型(language model)**。
语言模型能够捕捉到语言的 **潜在空间(laten space)**，即语言的统计结构。

一旦训练好了这样一个语言模型，就可以从中采样(sample, 即生成新序列)。
向模型中输入一个初始文本字符串(即条件数据(conditioning data))，
要求模型生成下一个字符或下一个单词(甚至可以同时生成多个标记)，然后将生成的输出添加到
输入数据中，并多次重复这一过程。这个循环可以生成任意长度的序列，这些序列反映了模型训练数据的结构，
它们与人类书写的句子几乎相同。

在本节的示例中，将会用到一个 LSTM 层，向其输入从文本语料中提取的 N 个字符组成的字符串，
然后训练模型来生成第 N + 1个字符。模型的输出是对所有可能的字符做 softmax，
得到下一个字符的的概率分布。这个 LSTM 叫作字符级的神经语言模型(character-level neural language model)。


