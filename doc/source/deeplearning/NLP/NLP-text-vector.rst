
NLP--文本向量化
=====================

1.概述
----------------------------------------------------------------

文本表示是 NLP 中的基础工作，文本表示的好坏直接影响到整个 NLP 系统的性能。
在 NLP 研究领域，文本向量化是文本表示的一种重要方式。

顾名思义，文本向量化就是将文本表示成一系列能够表达文本语义的向量，无论是中文还是英文，
词语都是表达文本处理的最基本单元，``word2vec`` 就是其中常用的方法。当前阶段，对文本向量化大
部分的研究都是通过词向量化实现的。

与此同时，也有相当一部分研究者将文章或者句子作为文本处理的基本单元，于是产生了 ``doc2vec`` 和
``str2vec``.

    - 基于统计的方法

    - 基于神经网络的方法

        - word2vec

        - doc2vec/str2vec

一般来说词语是表达语义的基本单元。因为词袋模型只是将词语符号化，所以词袋模型是不包含任何语义信息的。
    
    - 分布式假说(distributional hypothesis)的提出未解决上面的问题提供了理论基础。
      该假说的核心思想是：上下文相似的词，其语义也相似。随后有学者整理了利用上下文分布词表示词义的方法，
      这类方法就是有名的 **词空间模型(word space model)**。

    - 随着各类硬件设备计算能力的提升和相关算法的发展，神经网络模型逐渐在各个领域中崭露头角，
      可以灵活地对上下文进行建模是神经网络构造词表示的最大优点。

        - 通过语言模型构建上下文与目标词之间的关系是一种常见的方法。神经网络词向量模型就是根据上下文与目标词之间的关系进行建模。

2.词袋模型
-----------------------------------------------------------------

词袋(Bag Of Word)模型是最早的以词语为基本单元的文本向量化方法。下面举例说明该方法的原理:

1. 首先给出两个简单的文本如下:

    .. code-block:: 
    
        John likes to watch movies, Mary likes too.
        John also likes to watch football games.


2. 基于上述两个文档中出现的单词，构建如下词典(dictionary):

    .. code-block:: 

        {
            "John": 1, 
            "likes": 2,
            "to": 3,
            "watch": 4,
            "movies": 5,
            "also": 6,
            "football": 7,
            "games": 8,
            "Mary": 9,
            "too": 10,
        }

3. 上面词典中包含 10 个单词，每个单词有唯一的索引，那么每个文本可以使用一个 10 维的向量来表示:

    .. code-block:: 
    
        [1, 2, 1, 1, 1, 0, 0, 0, 1, 1]
        [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]

4. 上述向量与原来文本中单词出现的顺序没有关系，而是词典中每个单词在文本中出现的频率。该方法虽然简单易行，
但是存在如下三方面的问题：

    - 维度灾难

    - 无法保留词序信息

    - 存在语义鸿沟的问题


3.文本向量化算法
-----------------------------------------------------------------

3.1 神经网络语言模型
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

通过语言模型构建上下文与目标词之间的关系是一种常见的方法。神经网络词向量模型就是根据上下文与目标词之间的关系进行建模。

**神经网路语言模型(Neural Network Language Model, NNLM)** 与传统方法估算 :math:`P(\omega_{i}|\omega_{i-(n-1), \cdot, \omega_{i-1}})` 
不同，NNLM 模型直接通过一个神经网络结构对 :math:`n` 元条件概率进行估计。NNLM 模型的基本结构如下：




3.2 C&W 模型
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



3.3 word2vec CBOW 模型和 Skip-gram 模型
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~




3.4 doc2vec/str2vec
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~




4.文本向量化示例
-----------------------------------------------------------------


技术：

    - gensim

        - word2vec

        - doc2vec

1. 词向量的训练

    - 目标:

        - 对中文语料进行预处理

        - 利用 ``gensim`` 模块训练词向量


7.自然语言处理与词向量
----------------------

   自然语言处理主要研究使用计算机来处理、理解以及运用人类语言的各种理论和方法,属于人工智能的一个重要研究方向；


7.1 词汇表征
~~~~~~~~~~~~


7.2 词向量与语言模型
~~~~~~~~~~~~~~~~~~~~


8.word2vec 词向量
-----------------------------

   从深度学习的角度看,假设将 NLP 的语言模型看作是一个监督学习问题：给定上下文词 :math:`X`,输出中间词 :math:`Y`；
   或者给定中间词 :math:`X`,输出上下文词 :math:`Y`.基于输入 :math:`X` 和输出 :math:`Y` 之间的映射便是语言模型.
   这样的一个语言模型的目的便是检查 :math:`X` 和 :math:`Y` 放在一起是否符合自然语言规则,更通俗一点就是 :math:`X` 和
   :math:`Y` 放在一起是不是人话.

   所以,基于监督学习的思想,word2vec 便是一种基于神经网络训练的自然语言模型.word2vec 是谷歌于 2013 年提出的一种 NLP
   工具,其特点就是将词汇进行向量化,这样就可以定量的分析和挖掘词汇之间的联系.因而 word2vec 也是词嵌入表征的一种,
   只不过这种向量表征需要经过神经网络训练得到.

   word2vec 训练神经网路得到的一个关于输入 :math:`X` 和输出 :math:`Y` 之间的语言模型,关注的重点并不是说要把这个模型训练的有多好,
   而是要获取训练好的神经网络权重,这个权重就是我们要拿来对输入词汇 :math:`X` 的向量化表示.一旦拿到了训练预料所有词汇的词向量,接下来开展
   NLP 分析工作就相对容易一些.


9.词向量的训练
--------------------
