.. _header-n0:

优化算法
========

.. _header-n3:

1.学习算法优化
--------------

   深度学习算法在很多种情况下都涉及优化。在深度学习涉及的诸多优化问题中，最难的是神经网络训练，这里的学习算法优化就特指神经网络训练中的优化问题：寻找神经网络上的一组参数
   :math:`\theta`\ ，它能显著地降低代价函数
   :math:`J(\theta) = E_{(x, y) \backsim \hat{p}_{data}}L(f(x;\theta), y)`\ ，该代价函数通常包括整个训练集上的性能评估和额外的正则化项.

.. _header-n7:

1.1 经验风险最小化
~~~~~~~~~~~~~~~~~~

.. _header-n10:

1.2 代理损失函数和提前终止
~~~~~~~~~~~~~~~~~~~~~~~~~~

.. _header-n13:

1.3 批量算法和小批量算法
~~~~~~~~~~~~~~~~~~~~~~~~

1.梯度下降算法(Gradient Descent, GD) 2.小批量梯度下降算法(mini-batch
Gradient Descent, ):

在实际的数据应用场景，直接对大批量数据执行梯度下降法训练模型时，机器处理数据的速度会非常缓慢，这时将训练数据集分割成小一点的子集进行多次训练非常重要。这个被分割成的小的训练数据子集就做
mini-batch,意为小批量。对每个小批量数据集同时执行梯度下降法会大大提高训练效率。在实际利用代码实现的时候，小批量梯度下降算法通常包括两个步骤：充分打乱数据(shuffle)和分组组合数据【分区】(partition)。

3.随机梯度下降算法(Stochastic Gradient Descent, SGD)
4.带动量的梯度下降算法(Gradient Descent with Momentum)
5.自适应矩估计(Adaptive Moment Estimation, Adam)
6.加速梯度下降算法(RMSprop)

.. _header-n17:

2. 神经网络优化中的挑战
-----------------------

.. _header-n22:

1.最优化方法：模型参数更新
--------------------------

**机器学习、深度学习的数学本质:**

机器学习和神经网络的学习的目的是：从训练数据中“学习”，找到使得损失函数的值尽可能小的参数。这是寻找最优参数的问题，解决这个问题的过程称为\ **最优化(optimization)**\ 。对于大部分的有显式的损失函数表达式而言的机器学习问题，其数学本质都是最优化问题。这也是为什么数学是机器学习和深度学习的基础的原因所在。任何机器学习方法都是由以下三要素构成的：

-  **模型**\ ：机器学习在所有的模型空间中要采用的模型类别，比如说线性回归和感知机模型；

-  **策略**\ ：机器学习方法按照什么的标准去选择最优的模型，通常我们也叫模型评估方法，比如说线性回归的平方损失函数，策略就是要让平方损失函数取到最小值；

-  **算法**\ ：对于策略所选的损失函数采用什么方法取到最小值，即用什么样的计算方法求解最优模型，也就是最优化问题。比如说求解平方损失的最小二乘法以及梯度下降法；

当为一个机器学习(包括深度学习)方法选择好了模型类别和策略时，机器学习便形式化为一个最优化问题。这些针对损失函数的优化问题，有的是凸函数优化，有的是非凸函数优化。需要找到一些高效的算法对损失函数的优化问题进行求解。

线性模型和神经网络最大的区别在于神经网络的非线性导致大多数的损失函数都变得非凸。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得损失函数达到一个非常小的值，而不是像用于训练线性回归模型的线性方程求解器，或者用于训练逻辑回归或SVM的凸优化算法那样保证全局收敛。

凸优化从任何一种初始参数出发都会收敛(理论上如此，在实践中也很鲁棒但可能会遇到数值问题)。用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感。对于深度前馈网络，将所有的权重值初始化为小随机数是很重要的，而偏置一般初始化为0或者小的正值。

.. _header-n35:

2.损失函数
----------

.. _header-n36:

2.1 损失函数
~~~~~~~~~~~~

为了使用基于梯度的学习方法，必须选择一个损失函数，并且必须选择如何表示模型的输出。下面给出基于不同学习任务常用的损失函数：

+------+------+------+----------+
| 任务 | 符号 | 名字 | 数学形式 |
+======+======+======+==========+
| 分类 |      |      |          |
+------+------+------+----------+
| 回归 |      |      |          |
+------+------+------+----------+

**神经网络损失函数 - 交叉熵损失函数(cross entropy)：**

1. 在大多数情况下，参数模型定义了一个分布
   :math:`p(y|x;\theta)`\ ，并且简单地使用极大似然原理，这意味着使用\ **训练数据和模型预测间的交叉熵**\ 作为损失函数；

2. 有时使用一个更简单的方法，不是预测 :math:`y`
   的完整概率分布，而是仅仅预测\ **在给定 :math:`x`
   的条件下，\ :math:`y` 的某种统计量**\ ；

3. 用于训练神经网络的完整的损失函数通常是在基本的机器学习损失函数的基础上结合一个正则项；

.. _header-n63:

2.1.1 均方误差损失函数(Mean Squared Error, MSE)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

若 :math:`p_{model}(y|x) = N(y;f(x;\theta), I)`:

:math:`J(\theta)=\frac{1}{2}E_{x,y \sim \hat{p}_{data}} ||y-f(x;\theta)||^{2} + const`

:math:`E=\frac{1}{2} \sum_{k}(y_k-t_k)^2`

其中：

-  :math:`y_k`: 神经网路的输出

-  :math:`t_k`: 正确的目标变量

-  :math:`k`: 数据的维数

.. code:: python

   def mean_squared_error(y, t):
   	error = 0.5 * np.sum((y - t) ** 2)

   	return error

.. _header-n77:

2.1.2 交叉熵误差损失函数(Cross Entropy Error, CEE)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

:math:`L = -\frac{1}{n}\sum_{i=0}^{n}(y_i\log a_i + (1-y_i \log (1-a_i)))`

:math:`E=-\sum_{k}t_k\log y_k`

-  :math:`y_k`: 神经网路的输出

-  :math:`t_k`: 正确的解标签, {0, 1}

-  :math:`k`: 数据的维数

.. code:: python

   def cross_entropy_error(y, t):
   	delta = 1e-7
   	error = - np.sum(t * np.log(y + delta))

   	return error

.. _header-n89:

2.1.3 使用极大似然学习条件分布
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

大多数现代的神经网络使用极大似然来训练，这意味着损失函数就是负的对数似然，它与训练数据和模型分布间的交叉熵等价，这个损失函数表示为：

:math:`J(\theta)=E_{x,y \sim \hat{p}_{data}} \log p_{model}(y|x)`

损失函数的具体形式随着模型而改变，取决于 :math:`\log p_{model}` 的形式。

使用极大似然来导出损失函数的方法的一个优势是，它减轻了为每个模型设计损失函数的负担。明确一个模型
:math:`p(y|x)` 则自动地确定了一个损失函数 :math:`\log p(y|x)`\ 。

贯穿神经网络设计的一个反复出现的主题是损失函数的梯度必须足够的大和具有足够的预测性，来为学习算法提供一个好的指引。饱和(变得非常平)的的函数破坏了这一目标，因为它们把梯度变得非常小，这在很多情况下都会发生，因为用于产生隐藏单元或者输出单元的输出激活函数会饱和。负的对数似然帮助在很多模型中避免这个问题。

对于交叉熵损失函数的优化，通常采用基于\ ``梯度下降``\ 的算法框架对其进行优化迭代求解。这其中除了原始的梯度下降法之外，根据一次优化所需要的样本量的不同又可分为\ ``随机梯度下降``\ 和\ ``小批量（mini-batch）梯度下降``\ 。之后又引入了\ ``带有历史梯度加权的带动量（momentum）的梯度下降法``\ 、\ ``Rmsprop``
以及声名远扬的 ``Adam 算法``\ 等等：

-  梯度下降(Gradient Descent)

-  随机梯度下降 (Stoictic Gradient Descent)

-  小批量梯度下降(mini-batch Gradient Descent)

-  带有历史梯度加权的带动量的梯度下降法 ()

-  Rmsprop

-  Adam

.. _header-n110:

2.1.4 学习条件统计量
^^^^^^^^^^^^^^^^^^^^

.. _header-n112:

2.1.5 mini-batch学习
^^^^^^^^^^^^^^^^^^^^

   -  机器学习使用训练数据进行学习，严格来说就是针对训练数据计算损失函数的值，找出使该损失函数的值最小的参数。因此，计算损失函数时必须将所有的训练数据作为对象。

   -  针对所有训练数据的损失函数：

   -  均方误差：\ :math:`E = \frac{1}{2}\sum_n \sum_k (y_{nk} - t_{nk})^2`
      :math:`n`\ 为训练数据的个数

   -  交叉熵：\ :math:`E = -\frac{1}{n}\sum_n \sum_k t_{nk}\log y_{nk}`,
      :math:`n`\ 为训练数据的个数

   -  通过对所有训练数据的损失函数除以
      :math:`n`,可以求得单个数据的“平均损失函数”，通过这样的平均化，可以获得和训练数据的数量无关的统一指标；

   -  在训练数据数量比较大时，如果以全部数据为对象求损失函数，计算过程需要花费较长的时间，且对计算机空间的要求也会比较高。

   -  从全部数据中选出一部分，作为全部数据的“近似”，对小部分数据进行学习，叫做\ ``mini-batch学习``\ ；

.. _header-n132:

2.1.6 mini-batch交叉熵
^^^^^^^^^^^^^^^^^^^^^^

.. code:: python

   def cross_entropy_error(y, t):
   	if y.ndim == 1:
   		t = t.reshape(1, t.size)
   		y = y.reshape(1, y.size)

   	batch_size = y.shape[0]
   	return -np.sum(t * np.log(y + 1e-7)) / batch_size

当监督数据是标签形式时：

.. code:: python

   def cross_entropy_error(y, t):
   	if y.ndim == 1:
   		t = t.reshape(1, t.size)
   		y = y.reshape(1, y.size)

   	batch_size = y.shape[0]
   	return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size

.. _header-n139:

3.梯度算法
----------

机器学习和神经网络的学习都是从训练数据集中学习时寻找最优参数(权重和偏置)，这里的最优参数就是损失函数取最小值时的参数。一般而言，损失函数很复杂，参数空间庞大，通过使用梯度来寻找损失函数最小值(或尽可能小的值)的方法就是\ **梯度法**\ 。

-  梯度表示的是一个函数在各点处的函数值减小最多的方向，因此，无法保证梯度所指的方向就是函数的最小值或者真正应该前进的方向。实际上在复杂的函数中，梯度指示的方向基本上都不是函数值最小处

   -  函数的极小值，最小值，鞍点(saddle point)的地方，梯度为0

      -  最小值是指全局最小值

      -  极小值是指局部最小值，也就是限定在某个范围内的最小值

      -  鞍点是从某个方向上看是极大值，从另一个方向上看则是极小值的点；

-  虽然梯度的方向并不一定指向最小值，但沿着它的方向能够最大限度地减小函数的值。因此，在寻找函数的最小值(或者尽可能小的值)的位置的任务中，要以梯度的信息为线索，决定前进的方向

.. _header-n157:

3.1 梯度算法
~~~~~~~~~~~~

在梯度算法中，函数的取值从当前位置沿着梯度方向前进一段距离，然后在新的地方重新求梯度，再沿着新梯度方向前进，如此反复，不断地沿着梯度方向前进，逐渐减小函数的值，梯度算法可以分为两种，但常用的是梯度下降算法：

-  梯度下降算法(gradient descent method)

-  梯度上升算法(gradient ascent method)

**梯度下降法算法的数学表示：**

:math:`\omega_i^{(t)} = \omega_i^{(t)} - \eta^{(t)} \frac{\partial l}{\partial \omega_i^{(t)}}`

其中：

-  :math:`\omega_i^{(t)}`\ ：在第 :math:`t` 轮迭代时的第 :math:`i`
   个参数；

-  :math:`l`\ ：损失函数；

-  :math:`\eta^{(t)}`\ ：第 :math:`t` 轮迭代时的学习率 (learning
   rate)，决定在一次学习中，应该学习多少，以及在多大程度上更新参数；实验表明，设定一个合适的
   learning rate 是一个很重要的问题：

   -  学习率过大，会发散成一个很大的值；

   -  学习率过小，基本上没怎么更新就结束了；

.. _header-n179:

3.2 神经网络学习算法
~~~~~~~~~~~~~~~~~~~~

**神经网络的学习步骤：**

   -  前提：

   -  神经网络存在合适的权重和偏置，调整权重和偏置以便你和训练数据的过程称为“学习”。

   -  步骤1：mini-batch

   -  从训练数据中随机选出一部分数据，这部分数据称为mini-batch。目标是减小
      mini-batch 的损失函数的值；

   -  步骤2：计算梯度

   -  为了减小 mini-batch
      的损失函数的值，需要求出各个权重参数的梯度；梯度表示损失函数的值减小最多的方向；

   -  步骤3：更新参数

   -  将权重参数沿梯度方向进行微小更新；

   -  步骤4：(重复)

   -  重复步骤1，步骤2，步骤3；

**梯度算法(Gradient Descent, GD)改进：**

   在深度学习实际的算法调优中，原始的梯度下降法一般不大好用。通常来说，工业环境下深度学习所处理的数据量都是相当大的。这时若直接使用原始版本的梯度下降，可能训练速度和运算效率会非常低。这时候就需要采取一些策略对原始的梯度下降法进行调整来加速训练过程

-  改进1：

   -  ``随机梯度下降：从GD到mini-batch GD, SGD``\ ；

   -  ``mini-batch GD``\ ：将训练数据划分为小批量(mini-batch)进行训练

      -  将训练集划分为一个个子集的小批量数据，相较于原始的整体进行梯度下降的方法，整个神经网络的训练效率会大大提高；

   -  ``SGD``\ ：如果批量足够小，小到一批只有一个样本，这时算法就是随机梯度下降(SGD)；

      -  使用随机梯度下降算法，模型训练起来会很灵活，数据中的噪声也会得到减小，但是随机梯度下降会有一个劣势就是失去了向量化运算带来的训练加速度，算法也较难收敛，因为一次只处理一个样本，虽然足够灵活但效率过于低下；

   -  在深度学习模型的实际处理中，选择一个合适的\ ``batch-size``\ 是一个比较重要的问题；

      -  一般而言需要视训练的数据量来定，也需要不断的试验。

         -  通常而言，batch-size 过小会使得算法偏向 SGD
            一点，失去向量化带来的加速效果，算法也不容易收敛；

         -  但若是盲目增大
            batch-size，一方面会比较吃内存，另一方面是梯度下降的方向很难再有变化，进而影响训练精度。

         -  所以一个合适的 batch-size
            对于深度学习的训练来说就非常重要，合适的batch-size
            会提高内存的利用率，向量化运算带来的并行效率提高，跑完一次
            epoch
            所需要的迭代次数也会减少，训练速度会加快。这便是小批量（mini-batch）梯度下降
            batch-size 的作用。

   -  无论是梯度下降法(GD)、小批量（mini-batch）梯度下降法还是随机梯度下降法(SGD)，它们的本质都是基于梯度下降的算法策略，三者的区别即在于执行一次运算所需要的样本量

-  改进2：

   -  ``动量梯度下降：从Momentum到Adam``

   -  ``Momentum GD``\ ：基于移动加权的思想，给梯度下降加上历史梯度的成分来进一步加快下降速度，这种基于历史梯度和当前梯度进行加权计算的梯度下降法便是动量梯度下降法（Momentum
      GD）；

      -  动量梯度下降算法公式：

.. _header-n255:

SGD
~~~

**SGD的数学表示：**

:math:`W \leftarrow W - \eta \frac{\partial L}{\partial W}`

其中：

-  :math:`W`: 需要更新的权重参数；

-  :math:`\frac{\partial L}{\partial W}`: 损失函数关于权重参数 :math:`W`
   的梯度；

-  :math:`\eta`: 学习率(learning rate)，事先决定好的值，比如:0.001,
   0.01；

**SGD的Python实现：**

.. code:: python

   class SGD:
   	def __init__(self, lr = 0.01):
   		self.lr = lr

   	def update(self, params, grads):
   		for key in params.keys():
   			params[key] -= self.lr * grads[key]

**SGD的缺点：**

-  低效

   -  如果损失函数的形状非均向(anisotropic)，比如呈延伸状，搜索的路径就会非常低效；

   -  SGD低效的根本原因是：梯度的方向并没有指向最小值的方向；

.. _header-n278:

Momentum SGD(动量随机梯度下降法)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

**Momentum SGD的数学表示：**

:math:`\upsilon \leftarrow \alpha \upsilon - \eta \frac{\partial L}{\partial W}`

:math:`W \leftarrow W + \upsilon`

其中：

-  :math:`W`: 需要更新的权重参数；

-  :math:`\frac{\partial L}{\partial W}`: 损失函数关于权重参数 :math:`W`
   的梯度；

-  :math:`\eta`: 学习率(learning rate)，事先决定好的值，比如:0.001,
   0.01；

-  :math:`\upsilon`:
   对应物理上的速度，\ :math:`\upsilon`\ 的更新表示了物体在梯度方向上受力，在这个力的作用下，物体的速度增加；

-  :math:`\alpha \upsilon`:
   对应了物理上的地面摩擦或空气阻力，表示在物体不受任何力时，该项承担使物体逐渐减速的任务(\ :math:`\alpha`
   一般设定为0.9)

**Momentum SGD的Python实现：**

.. code:: python

   class Momentum:
   	def __init__(self, lr = 0.01, momentum = 0.9):
   		self.lr = lr
   		self.momentum = momentum
   		self.v = None

   	def update(self, params, grads):
   		if self.v is None:
   			self.v = {}
   			for key, val in params.items():
   				self.v[key] = np.zeros_like(val)

   		for key in params.keys():
   			self.v[key] = self.momentum * self.v[key] - self.lr * self.grads[key]
   			params[key] += self.v[key]

**Momentum SGD的优缺点：**

-  为什么会好？

.. _header-n302:

AdaGrad
~~~~~~~

   -  在神经网络的学习中，学习率(learning rate, lr or
      :math:`\eta`)的值很重要。

   -  学习率过小，会导致学习花费过多的时间；

   -  学习率过大，会导致学习发散而不能正确进行；

   -  ``学习率衰减(learning rate decay)``\ ：随着学习的进行，使学习率逐渐减小；

   -  逐渐减小学习率的想法，相当于将“全体”参数的学习率一起降低；

   -  AdaGrad发展了学习率衰减的想法，针对一个一个的参数，赋予其“定制”的值；

   -  AdaGrad会为参数的每个元素适当地调整学习率，与此同时进行学习；

**AdaGrad SGD的数学表示：**

:math:`h \leftarrow h + \frac{\partial L}{\partial W} \odot \frac{\partial L}{\partial W}`

:math:`W \leftarrow W - \eta \frac{1}{\sqrt{h}} \frac{\partial L}{\partial W}`

其中：

-  :math:`W`: 需要更新的权重参数；

-  :math:`\frac{\partial L}{\partial W}`: 损失函数关于权重参数 :math:`W`
   的梯度；

-  :math:`\eta`: 学习率(learning rate)，事先决定好的值，比如:0.001,
   0.01；

-  :math:`h`:
   保存了以前所有梯度值的平方和，然后，在更新参数时，通过乘以\ :math:`\frac{1}{\sqrt{h}}`\ 就可以调整学习的尺度

   -  参数的元素中变动较大(被大幅更新)的元素的学习率将变小，也就是说，可以按照参数的元素进行学习率衰减，使变动的参数的学习率逐渐减小；

**AdaGrad SGD的Python实现：**

.. code:: python

   class AdaGrad:
   	def __init__(self, lr = 0.01):
   		self.lr = lr
   		self.h = None

   	def update(self, params, grads):
   		if self.h is None:
   			self.h = {}
   			for key, val in params.items():
   				self.h[key] = np.zeros_like(val)

   		for key in params.keys():
   			self.h[key] += grads[key] * grads[key]
   			param[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)

**AdaGrad SGD的优缺点：**

-  AdaGrad会记录过去所有梯度的平方和。因此，学习越深入，更新的幅度就越小。实际上，如果无止境地学习，更新量就会变为0，完全不再更新。

-  为了改善这个问题，可以使用RMSProp方法。RMSProp方法并不是将过去所有的梯度一视同仁地相加，而是逐渐地遗忘过去的梯度，在做加法运算时将新的梯度的信息更多地反映出来。这种操作从专业上讲，称为“指数移动平均”，呈指数函数式地减小过去的梯度的尺度。

.. _header-n350:

Adam
~~~~

   Adam融合了Momentum和AdaGrad的方法，通过组合两个方法的优点，有希望实现参数空间的高效搜索。
   并且Adam会进行超参数的“偏置校正”；

**Adam的数学表示：**

**Adam的Python实现：**

**Adam的优缺点：**

.. _header-n356:

RMSProp
~~~~~~~

**RMSProp的数学表示：**

**RMSProp的Python实现：**

**RMSProp的优缺点：**
