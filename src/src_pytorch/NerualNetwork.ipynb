{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "piano-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-piano",
   "metadata": {},
   "source": [
    "# 设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lesbian-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-shoulder",
   "metadata": {},
   "source": [
    "# 定义模型类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impossible-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "improving-ladder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "legal-atlanta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8827, 0.4748, 0.9980, 0.7501, 0.3412, 0.2546, 0.9781, 0.9938,\n",
       "          0.0226, 0.3049, 0.4617, 0.7838, 0.4322, 0.9491, 0.1079, 0.4271,\n",
       "          0.3812, 0.5430, 0.6718, 0.1848, 0.7810, 0.3025, 0.3734, 0.6175,\n",
       "          0.2002, 0.2370, 0.0329, 0.5553],\n",
       "         [0.6680, 0.5696, 0.9502, 0.0231, 0.6185, 0.0188, 0.7499, 0.9950,\n",
       "          0.0864, 0.9608, 0.9969, 0.7731, 0.5248, 0.1811, 0.5793, 0.0501,\n",
       "          0.6823, 0.9423, 0.9900, 0.0606, 0.4749, 0.7027, 0.7036, 0.0583,\n",
       "          0.9025, 0.6833, 0.8207, 0.8332],\n",
       "         [0.0324, 0.9485, 0.0987, 0.2267, 0.8979, 0.5660, 0.8757, 0.8633,\n",
       "          0.1018, 0.6406, 0.2479, 0.7821, 0.8969, 0.4096, 0.8256, 0.6529,\n",
       "          0.0945, 0.8785, 0.9574, 0.7622, 0.7375, 0.0898, 0.6492, 0.2897,\n",
       "          0.1735, 0.7475, 0.0142, 0.7195],\n",
       "         [0.8092, 0.3320, 0.3739, 0.0430, 0.1559, 0.7271, 0.3376, 0.1652,\n",
       "          0.2119, 0.1661, 0.7856, 0.2865, 0.8252, 0.4608, 0.5091, 0.4766,\n",
       "          0.5286, 0.0039, 0.6901, 0.7524, 0.9549, 0.5953, 0.5224, 0.1843,\n",
       "          0.1070, 0.7446, 0.1517, 0.4923],\n",
       "         [0.9321, 0.5168, 0.9548, 0.6511, 0.7872, 0.8742, 0.4821, 0.7256,\n",
       "          0.7952, 0.4915, 0.8018, 0.5879, 0.6604, 0.7647, 0.6116, 0.9036,\n",
       "          0.8369, 0.7028, 0.1509, 0.4219, 0.2091, 0.5925, 0.3214, 0.9734,\n",
       "          0.4669, 0.4409, 0.8895, 0.0483],\n",
       "         [0.4708, 0.4862, 0.6095, 0.8490, 0.1506, 0.0604, 0.2963, 0.4792,\n",
       "          0.1884, 0.9439, 0.0910, 0.2089, 0.4984, 0.0591, 0.4586, 0.5739,\n",
       "          0.1889, 0.5245, 0.3327, 0.5597, 0.3403, 0.9901, 0.5774, 0.1365,\n",
       "          0.3844, 0.8070, 0.3001, 0.5579],\n",
       "         [0.3743, 0.9081, 0.8980, 0.8329, 0.5158, 0.8095, 0.1536, 0.8765,\n",
       "          0.7711, 0.6903, 0.7581, 0.3270, 0.5821, 0.3187, 0.2307, 0.0324,\n",
       "          0.2175, 0.8301, 0.5136, 0.0462, 0.9184, 0.4587, 0.6306, 0.8605,\n",
       "          0.3819, 0.7825, 0.5387, 0.0809],\n",
       "         [0.0931, 0.9751, 0.6141, 0.5236, 0.3908, 0.8332, 0.2968, 0.4303,\n",
       "          0.4177, 0.3771, 0.2850, 0.0651, 0.3679, 0.8091, 0.0557, 0.5906,\n",
       "          0.8088, 0.3209, 0.4429, 0.6745, 0.5358, 0.7058, 0.4205, 0.8978,\n",
       "          0.7582, 0.8511, 0.2687, 0.9099],\n",
       "         [0.9430, 0.6816, 0.7185, 0.8312, 0.4308, 0.4977, 0.2751, 0.0447,\n",
       "          0.1480, 0.3783, 0.1515, 0.8018, 0.9790, 0.6838, 0.6918, 0.5946,\n",
       "          0.2379, 0.0903, 0.8076, 0.7662, 0.1020, 0.9077, 0.4376, 0.7919,\n",
       "          0.8220, 0.6260, 0.1723, 0.8769],\n",
       "         [0.4490, 0.7303, 0.5155, 0.8778, 0.3781, 0.2157, 0.1088, 0.9895,\n",
       "          0.2401, 0.8672, 0.1887, 0.8679, 0.7091, 0.8699, 0.3148, 0.4400,\n",
       "          0.6692, 0.9132, 0.1358, 0.0186, 0.2921, 0.3424, 0.2722, 0.1366,\n",
       "          0.6522, 0.1760, 0.8941, 0.8393],\n",
       "         [0.9757, 0.9015, 0.6833, 0.0979, 0.3846, 0.7038, 0.2777, 0.6334,\n",
       "          0.9322, 0.1796, 0.3669, 0.7314, 0.3104, 0.1393, 0.1890, 0.3743,\n",
       "          0.2329, 0.3868, 0.8025, 0.0233, 0.3774, 0.6845, 0.9060, 0.4866,\n",
       "          0.7541, 0.9261, 0.1969, 0.8500],\n",
       "         [0.0483, 0.5478, 0.6348, 0.7134, 0.6993, 0.6737, 0.3732, 0.4890,\n",
       "          0.6860, 0.8723, 0.9171, 0.3316, 0.4024, 0.1360, 0.0415, 0.7029,\n",
       "          0.4064, 0.4294, 0.1931, 0.4161, 0.3265, 0.5810, 0.8503, 0.3862,\n",
       "          0.8481, 0.0608, 0.1339, 0.1193],\n",
       "         [0.9410, 0.7878, 0.8612, 0.1138, 0.1497, 0.0478, 0.0525, 0.0807,\n",
       "          0.9966, 0.1451, 0.5807, 0.6544, 0.4206, 0.8149, 0.7551, 0.1285,\n",
       "          0.0585, 0.9761, 0.6170, 0.8073, 0.8624, 0.9485, 0.1641, 0.6137,\n",
       "          0.7187, 0.8562, 0.3341, 0.6774],\n",
       "         [0.5552, 0.0373, 0.8953, 0.2242, 0.5676, 0.3412, 0.1264, 0.6535,\n",
       "          0.9698, 0.4279, 0.7048, 0.9279, 0.7175, 0.5667, 0.7711, 0.4821,\n",
       "          0.9940, 0.3240, 0.1899, 0.0688, 0.1863, 0.8202, 0.1264, 0.1479,\n",
       "          0.2824, 0.6597, 0.1048, 0.0817],\n",
       "         [0.6890, 0.4055, 0.8300, 0.9085, 0.4338, 0.0396, 0.1987, 0.0573,\n",
       "          0.0299, 0.4863, 0.2719, 0.7065, 0.8585, 0.0970, 0.9873, 0.7931,\n",
       "          0.6110, 0.7414, 0.8268, 0.6300, 0.7630, 0.6762, 0.9694, 0.3544,\n",
       "          0.8484, 0.2887, 0.0762, 0.4184],\n",
       "         [0.5300, 0.0165, 0.5169, 0.2165, 0.1539, 0.6411, 0.7270, 0.9317,\n",
       "          0.3865, 0.5099, 0.6359, 0.4071, 0.2134, 0.6171, 0.6763, 0.2439,\n",
       "          0.6150, 0.0131, 0.9086, 0.1993, 0.4572, 0.8224, 0.3150, 0.3509,\n",
       "          0.1880, 0.7244, 0.2155, 0.2998],\n",
       "         [0.2598, 0.7483, 0.7379, 0.6645, 0.1244, 0.1196, 0.2969, 0.0728,\n",
       "          0.3890, 0.9392, 0.3714, 0.5356, 0.9204, 0.4198, 0.3874, 0.2168,\n",
       "          0.8888, 0.6995, 0.9070, 0.0432, 0.5005, 0.2616, 0.6329, 0.2023,\n",
       "          0.8383, 0.1830, 0.3810, 0.1418],\n",
       "         [0.4671, 0.6021, 0.3968, 0.6593, 0.2813, 0.2145, 0.3256, 0.7240,\n",
       "          0.3367, 0.9145, 0.9219, 0.2853, 0.9394, 0.4184, 0.5442, 0.5127,\n",
       "          0.8378, 0.5937, 0.4958, 0.8287, 0.3606, 0.5423, 0.6500, 0.5142,\n",
       "          0.3733, 0.7874, 0.9322, 0.1722],\n",
       "         [0.4638, 0.1444, 0.4400, 0.7360, 0.0130, 0.0189, 0.9144, 0.4511,\n",
       "          0.4368, 0.7028, 0.9768, 0.3036, 0.0095, 0.5002, 0.6321, 0.3585,\n",
       "          0.4413, 0.1844, 0.2230, 0.6859, 0.1430, 0.1926, 0.3946, 0.4173,\n",
       "          0.3616, 0.6308, 0.7770, 0.3234],\n",
       "         [0.1539, 0.0262, 0.4052, 0.9375, 0.5425, 0.6852, 0.7455, 0.5736,\n",
       "          0.8876, 0.0558, 0.2988, 0.5697, 0.7426, 0.2924, 0.7559, 0.6614,\n",
       "          0.3009, 0.7385, 0.8228, 0.7113, 0.0912, 0.3316, 0.9426, 0.0120,\n",
       "          0.5820, 0.8541, 0.3185, 0.2885],\n",
       "         [0.3534, 0.4571, 0.9969, 0.2337, 0.8648, 0.5302, 0.6002, 0.3040,\n",
       "          0.0233, 0.3082, 0.9873, 0.5972, 0.7704, 0.4288, 0.0466, 0.9489,\n",
       "          0.6799, 0.3356, 0.1642, 0.8972, 0.4772, 0.8431, 0.0623, 0.0644,\n",
       "          0.5036, 0.5424, 0.4438, 0.1995],\n",
       "         [0.4779, 0.7913, 0.7763, 0.4071, 0.3994, 0.9050, 0.2393, 0.9303,\n",
       "          0.0858, 0.5097, 0.7853, 0.7532, 0.0925, 0.9050, 0.0353, 0.5657,\n",
       "          0.6317, 0.1393, 0.2801, 0.6332, 0.3470, 0.6987, 0.1029, 0.8951,\n",
       "          0.0657, 0.4312, 0.8929, 0.5467],\n",
       "         [0.8687, 0.0538, 0.8470, 0.5305, 0.8979, 0.1242, 0.8480, 0.1441,\n",
       "          0.2269, 0.5485, 0.5394, 0.8082, 0.8274, 0.1226, 0.4331, 0.8016,\n",
       "          0.2222, 0.6474, 0.8672, 0.6062, 0.5631, 0.0969, 0.5447, 0.0863,\n",
       "          0.1622, 0.5975, 0.3384, 0.9743],\n",
       "         [0.1205, 0.6395, 0.5008, 0.0090, 0.2064, 0.3054, 0.6337, 0.6815,\n",
       "          0.1514, 0.0872, 0.7206, 0.8367, 0.1616, 0.3124, 0.4037, 0.5623,\n",
       "          0.0087, 0.2954, 0.8147, 0.3486, 0.5166, 0.0641, 0.9006, 0.1140,\n",
       "          0.3690, 0.7876, 0.0354, 0.1003],\n",
       "         [0.4875, 0.3501, 0.6050, 0.2100, 0.8623, 0.5948, 0.3983, 0.9213,\n",
       "          0.5364, 0.2645, 0.2011, 0.1838, 0.2001, 0.8948, 0.3750, 0.1416,\n",
       "          0.7823, 0.4308, 0.5652, 0.7163, 0.5292, 0.5630, 0.9436, 0.0899,\n",
       "          0.5389, 0.0334, 0.8323, 0.5714],\n",
       "         [0.2112, 0.9888, 0.5723, 0.5879, 0.9051, 0.5058, 0.6666, 0.4860,\n",
       "          0.8951, 0.1040, 0.5718, 0.7281, 0.6063, 0.9128, 0.7422, 0.4557,\n",
       "          0.7155, 0.0832, 0.2467, 0.1401, 0.5213, 0.6875, 0.8746, 0.4871,\n",
       "          0.9299, 0.6860, 0.1932, 0.6916],\n",
       "         [0.0142, 0.9565, 0.0932, 0.2457, 0.2329, 0.4949, 0.1723, 0.6555,\n",
       "          0.6807, 0.6541, 0.9072, 0.5151, 0.6742, 0.1181, 0.9689, 0.4193,\n",
       "          0.9669, 0.0954, 0.8971, 0.5357, 0.6010, 0.5655, 0.8441, 0.5600,\n",
       "          0.4328, 0.3911, 0.1786, 0.4001],\n",
       "         [0.3953, 0.1032, 0.6670, 0.6236, 0.1658, 0.3272, 0.3463, 0.2976,\n",
       "          0.0346, 0.8863, 0.2260, 0.8738, 0.5973, 0.8104, 0.7979, 0.7132,\n",
       "          0.5501, 0.5755, 0.8685, 0.9327, 0.6627, 0.1711, 0.8451, 0.2705,\n",
       "          0.0477, 0.9557, 0.1295, 0.2770]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device = device)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nominated-analyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0617, -0.0297, -0.0450, -0.0357,  0.0159,  0.1208, -0.0814,  0.0692,\n",
       "          0.0459,  0.0449]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(X)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nearby-hazard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1044, 0.0953, 0.0939, 0.0947, 0.0997, 0.1108, 0.0905, 0.1052, 0.1028,\n",
       "         0.1027]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab = nn.Softmax(dim = 1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "experienced-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([5])\n"
     ]
    }
   ],
   "source": [
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-shock",
   "metadata": {},
   "source": [
    "# 模型层(Model Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recreational-clothing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9696, 0.5141, 0.2983,  ..., 0.7696, 0.6447, 0.7344],\n",
      "         [0.6044, 0.8782, 0.2120,  ..., 0.4860, 0.2735, 0.7714],\n",
      "         [0.5112, 0.3912, 0.7548,  ..., 0.7118, 0.7205, 0.9916],\n",
      "         ...,\n",
      "         [0.7035, 0.6355, 0.3708,  ..., 0.7702, 0.2575, 0.1311],\n",
      "         [0.0036, 0.0127, 0.0460,  ..., 0.3576, 0.9409, 0.4055],\n",
      "         [0.0094, 0.6050, 0.7607,  ..., 0.1117, 0.9697, 0.1607]],\n",
      "\n",
      "        [[0.9388, 0.1084, 0.2759,  ..., 0.8164, 0.6986, 0.1027],\n",
      "         [0.6053, 0.3331, 0.4235,  ..., 0.3879, 0.9233, 0.1842],\n",
      "         [0.5291, 0.6479, 0.5161,  ..., 0.0524, 0.5421, 0.8979],\n",
      "         ...,\n",
      "         [0.7359, 0.8663, 0.1267,  ..., 0.4311, 0.2346, 0.3589],\n",
      "         [0.3783, 0.8926, 0.2386,  ..., 0.5808, 0.1326, 0.7208],\n",
      "         [0.0141, 0.6932, 0.9330,  ..., 0.4348, 0.0702, 0.6941]],\n",
      "\n",
      "        [[0.1275, 0.0396, 0.1776,  ..., 0.1419, 0.2053, 0.4277],\n",
      "         [0.4060, 0.2681, 0.2468,  ..., 0.6681, 0.0429, 0.4476],\n",
      "         [0.2458, 0.1886, 0.4635,  ..., 0.8668, 0.5022, 0.3348],\n",
      "         ...,\n",
      "         [0.3121, 0.1519, 0.8611,  ..., 0.8522, 0.7572, 0.2636],\n",
      "         [0.0906, 0.1479, 0.6979,  ..., 0.3548, 0.1215, 0.8495],\n",
      "         [0.1336, 0.7131, 0.0751,  ..., 0.2199, 0.4471, 0.8260]]])\n",
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-location",
   "metadata": {},
   "source": [
    "## nn.Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "champion-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-founder",
   "metadata": {},
   "source": [
    "## nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dominican-extraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features = 28 * 28, out_features = 20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-schedule",
   "metadata": {},
   "source": [
    "## nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "flying-cotton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.2668,  0.0135,  0.4409, -0.1953, -0.0484,  0.1787,  0.3525,  0.2317,\n",
      "          0.1331,  0.3980,  0.2933, -0.4499,  0.3150, -0.0141,  0.0278,  0.0193,\n",
      "          0.5590, -0.6276,  0.6792, -0.2618],\n",
      "        [-0.0089,  0.4920,  0.3460,  0.1253, -0.0807, -0.5219,  0.4012,  0.1189,\n",
      "          0.2139,  0.7205, -0.0409, -0.0898, -0.2142, -0.1771, -0.0727, -0.1149,\n",
      "          0.3644, -1.1675,  0.4720, -0.6212],\n",
      "        [ 0.3056,  0.3765, -0.0782, -0.1295,  0.1011,  0.2607,  0.1800, -0.1392,\n",
      "          0.1598,  0.5965,  0.0977, -0.5815,  0.1223, -0.3159,  0.1340, -0.0624,\n",
      "          0.7305, -0.3004,  0.3221, -0.2867]], grad_fn=<AddmmBackward>) \n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0135, 0.4409, 0.0000, 0.0000, 0.1787, 0.3525, 0.2317, 0.1331,\n",
      "         0.3980, 0.2933, 0.0000, 0.3150, 0.0000, 0.0278, 0.0193, 0.5590, 0.0000,\n",
      "         0.6792, 0.0000],\n",
      "        [0.0000, 0.4920, 0.3460, 0.1253, 0.0000, 0.0000, 0.4012, 0.1189, 0.2139,\n",
      "         0.7205, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3644, 0.0000,\n",
      "         0.4720, 0.0000],\n",
      "        [0.3056, 0.3765, 0.0000, 0.0000, 0.1011, 0.2607, 0.1800, 0.0000, 0.1598,\n",
      "         0.5965, 0.0977, 0.0000, 0.1223, 0.0000, 0.1340, 0.0000, 0.7305, 0.0000,\n",
      "         0.3221, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1} \\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-inflation",
   "metadata": {},
   "source": [
    "## nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "listed-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0911,  0.2999,  0.0753,  0.3999, -0.0911, -0.0645, -0.0314,  0.1037,\n",
       "         -0.0436,  0.2484],\n",
       "        [ 0.0618,  0.2854,  0.2894,  0.2883,  0.0167, -0.1007, -0.0255,  0.1706,\n",
       "         -0.1682,  0.2510],\n",
       "        [ 0.0682,  0.3409,  0.2841,  0.2363, -0.0614, -0.0487, -0.0891,  0.1501,\n",
       "         -0.1821,  0.3231]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-minnesota",
   "metadata": {},
   "source": [
    "## nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "colonial-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim = 1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-sucking",
   "metadata": {},
   "source": [
    "# 模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "royal-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bridal-singing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[ 0.0071, -0.0298,  0.0350,  ...,  0.0129,  0.0348, -0.0097],\n",
      "        [ 0.0039, -0.0301,  0.0322,  ..., -0.0100, -0.0226, -0.0144]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([0.0139, 0.0281], grad_fn=<SliceBackward>)\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[-0.0183, -0.0186,  0.0114,  ..., -0.0048, -0.0327, -0.0207],\n",
      "        [ 0.0051,  0.0205,  0.0393,  ..., -0.0163, -0.0269,  0.0401]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([-0.0383, -0.0090], grad_fn=<SliceBackward>)\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[-0.0339,  0.0023, -0.0093,  ..., -0.0040, -0.0350, -0.0427],\n",
      "        [ 0.0287,  0.0422,  0.0421,  ..., -0.0397,  0.0437,  0.0196]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([-0.0241, -0.0328], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-season",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
